# Radiologist-Scheduling-Agent
A web application that converts free-form natural-language notes from radiologists into a balanced on-call rotation. Two core components underpin the system:

1. **Large-language-model (LLM) agents** (OpenAI GPT models) ‚Äî transform narrative notes into structured, machine-readable constraints.  
2. **CP-SAT optimisation model** (Google OR-Tools) ‚Äî produces a schedule that satisfies all hard rules and minimises specified soft penalties.

‚∏ª

## 1 Repository structure

```text
Radiologist-Scheduling-Agent/
‚îú‚îÄ home.py                          ‚Üê Streamlit user interface (entry point)
‚îÇ
‚îú‚îÄ utils/
‚îÇ   ‚îú‚îÄ Ollama_Agent.py
‚îÇ   ‚îî‚îÄ OpenAI_Agent.py
‚îÇ
‚îú‚îÄ data/
‚îÇ   ‚îú‚îÄ Example.csv
‚îÇ   ‚îî‚îÄ Sample_Reports.csv
‚îÇ
‚îî‚îÄ README.md
```


‚∏ª

## 2‚ÄÇSystem overview

| **Stage** | **Principal module(s)** | **Summary** |
|-----------|-------------------------|-------------|
| **Data ingestion** | `home.py` | User chooses a model, output format, and single or multi- agent functionality. User then edit prompts to agent(s) and provides resident and attending reports in the provided text boxes. |
| **Agent Call and Analysis** | `utils/Ollama_Agent.py`, `OpenAI_Agent.py` | Agent(s) analyze resident and attending reports and provide an output summarizing the adjustments made to the resident report by the attending. |
| **Presentation layer** | `home.py` | Properly formats the output strings of the agent call and produces wither a sectioned paragraph output or a table output summarizing report adjustments. |

‚∏ª

## 3‚ÄÇInstallation and execution

### 3.1‚ÄÇEnvironment setup

<pre lang="markdown">

<code>
git clone https://github.com/rlacs235711/Radiologist-Scheduling-Agent.git
cd Radiologist-Scheduling-Agent

python3 -m venv .venv
source .venv/bin/activate

# Install necessary packages:
pip install -r requirements.txt

# Set your OpenAI API key
export OPENAI_API_KEY=&lt;your-key&gt;
</code>

</pre>

### 3.2‚ÄÇStarting the application
<pre lang="markdown">

<code>
streamlit run ./home.py
</code>

</pre>

The application should open automatically; if not, open the URL shown in the terminal.

‚∏ª

## 4‚ÄÇOperating the application
### 1.	Choose the desired output settings: model, output type, single or multi-agent functionality
### 2.	Edit pre-existing agent prompts (optional)
### 3.	Provide resident and attending reports in the corresponding text boxes
### 4.  Click `Analyze` and wait for output to appear
### 5. Click `üì• Download All Results as CSV` to save all previous inputs and outputs to a csv file

‚∏ª

## 6‚ÄÇDependencies

The project runs using Python 3.9 + and relies on the following core packages:

| Package         | Purpose                                              |
|----------------|------------------------------------------------------|
| `openai`        | Access to GPT models for parsing tasks              |
| `streamlit`     | Web UI framework                                    |
| `pandas`        | CSV processing                                      |
| `python-dotenv` | Local `.env` management for `OPENAI_API_KEY` (optional) |

Additionally, relevant LLM's downloaded from Ollama are listed below:
### - deepseek-r1:70b
### - llama3.3:latest
### - llama3.2-vision:90b
### - gemma3:27b

New models can be downloaded and utilized by editing the `OLLAMA_MODEL` list in `home.py`.
